{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d35c69-d0be-402b-be8a-5faa7345e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1454e4df-3815-4e88-ac79-d3c212bc104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test) =  imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c534357d-b44a-4456-b8d9-9e5f41f01d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88586"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key = max(max([max(sentence) for sentence in X_train]),max([max(sentence) for sentence in X_test]))\n",
    "max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8ddbd3-c89f-4625-be18-bb3fd829e5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "max_vlaue = max(word_index.values())\n",
    "max_vlaue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640fff54-099f-4866-ac9c-efca7be07f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944ca9cf-1bb8-43af-beef-bbaa8d594fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_sentences(X_train):\n",
    "input : np.array: ([123,12,15,48],[51,74,63], ...)\n",
    "output : list:['text', 'text', ...]\n",
    "\n",
    "\n",
    "동작\n",
    "\n",
    "np 어레이를 리스트로 typecasting 후\n",
    "내부 리스트 하나씩(sentence) 읽어와서\n",
    "원소(index) 하나씩 단어사전(index_word) 참조\n",
    "만약 index가 사전에 최댓값 보다 크다면 \n",
    "사전 참조하지 않고 continue\n",
    "단어 단위를 더할때에는 사이에 공백(' ')추가\n",
    "리스트에 문장을 넣을 때 양 끝에 공백 벗기고(.strip())추가\n",
    "리스트 반환\n",
    "\n",
    "\"\"\"\n",
    "def make_sentences(dummy):\n",
    "    dummy_list = []\n",
    "    for sentence in list(dummy):\n",
    "        context = ''\n",
    "        for index in sentence:\n",
    "            if index > max_vlaue:\n",
    "                continue\n",
    "            context += index_word[index]+' '\n",
    "        dummy_list.append(context.strip())\n",
    "    return dummy_list\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "contexts_to_index(sentence_list):\n",
    "input: text_list: ['abc asv', 'bdvs brrwab brb', ...] \n",
    "output: index_list: [[1594, 2456, 24154, 1514, 1248, 12],[154,87,7,213,8], ...]\n",
    "\n",
    "동작\n",
    "인덱스리스트의 내부 리스트(sentence)를 하나씩 가져와서\n",
    "만약 sentence에 공백이 존재하면 (하나 이상의 단어라는 의미)\n",
    "word_list를 sentence.split으로 생성 단어 리스트\n",
    "단어리스트를 보면서 index_word를 사전참조해\n",
    "tmp에 append\n",
    "tmp를 index_list에 담는다.\n",
    "\n",
    "만약 공백이 존재하지 않으면? --> 단일 단어\n",
    "바로 index_word에 사전참조하여 [리스트에 담아서] index_list에 담는다.\n",
    "\n",
    "index_list 반환\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def contexts_to_index(sentence_list):\n",
    "    index_list = []\n",
    "    for sentence in sentence_list:\n",
    "        if \" \" in sentence:\n",
    "            tmp = []\n",
    "            word_list = sentence.split()\n",
    "            for word in word_list:\n",
    "                try:\n",
    "                    tmp.append(word_index[word])\n",
    "                except:\n",
    "                    try:\n",
    "                        tmp.append(word_index[word.strip()])\n",
    "                    except:\n",
    "                        pass\n",
    "                    # 만약 안되면 추가\n",
    "                    tmp.append(0)\n",
    "            index_list.append(tmp)\n",
    "        else:\n",
    "            index_list.append([word_index[sentence]])\n",
    "    return index_list\n",
    "\n",
    "\"\"\"\n",
    "make_full_text(sentence_list):\n",
    "input:\n",
    "output:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def make_full_text(sentence_list):\n",
    "    full_text = ''\n",
    "    for sentence in sentence_list:\n",
    "        full_text += sentence + ' '\n",
    "    return full_text.strip()\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d8080f-dda0-4e23-befb-52783a92b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = make_sentences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a988887-648a-44bc-bcdc-50addf4205c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 과정으로 테스트케이스도 데이터 변환을 해준다.\n",
    "test_text  = make_sentences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac643e30-15db-4ec3-af68-a3e1c6764f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the as you with out themselves powerful lets l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the thought solid thought senator do making to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the as there in at by br of sure many br of pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the of bernadette mon they halfway of identity...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the sure themes br only acting i i was favouri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>the as it is ludicrous on not rape br program ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>the slaughter susan effects is following like ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>the this is anything tv tormented it is genera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>the bar reverse me we endearing was song deep ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>the movie is thought completely br of i've you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      the as you with out themselves powerful lets l...      1\n",
       "1      the thought solid thought senator do making to...      0\n",
       "2      the as there in at by br of sure many br of pr...      0\n",
       "3      the of bernadette mon they halfway of identity...      1\n",
       "4      the sure themes br only acting i i was favouri...      0\n",
       "...                                                  ...    ...\n",
       "24995  the as it is ludicrous on not rape br program ...      1\n",
       "24996  the slaughter susan effects is following like ...      0\n",
       "24997  the this is anything tv tormented it is genera...      0\n",
       "24998  the bar reverse me we endearing was song deep ...      1\n",
       "24999  the movie is thought completely br of i've you...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(text, columns=['text'])\n",
    "data['label'] = y_train\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3d2885-67d1-4b87-891f-8ae2ecf54be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 훈련데이터로 전체 텍스트 만들기\n",
    "full_text = make_full_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e721c14-83a7-4775-872f-b7fd57b94d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "훈련데이터에서\n",
    "가장 많이 사용된 단어 10000개 찾기\n",
    "\"\"\"\n",
    "counter = Counter(full_text.split())\n",
    "common_word =[i for i,j in counter.most_common(10000)]\n",
    "\n",
    "# 유니크하게 바꾸기 (중복제거)\n",
    "unique_word = list(set(common_word))\n",
    "\n",
    "# enumerate로 새로운 word_index 사전 생성\n",
    "index_word = { k+1:v for k, v in enumerate(unique_word)}\n",
    "word_index = {v:k for k,v in index_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc29bb5-08ea-41cd-a6c4-6af99863d951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexed_sentece = contexts_to_index(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af6db9c-458a-4002-a86c-b71b236a0a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 같은 과정으로 테스트케이스도 데이터 변환을 해준다.\n",
    "test_sentence = contexts_to_index(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "917450c6-2d2e-49f6-96a3-a602a0d2b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = vectorize_sequences(indexed_sentece,10001)\n",
    "# 같은 과정으로 테스트케이스도 데이터 변환을 해준다.\n",
    "test = vectorize_sequences(test_sentence,10001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c56cd4-7a2f-4a8b-8412-a70207931f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train[:1000]\n",
    "partial_x_train = train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419099e5-9dda-42e2-a7bd-91909beaf6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 14:04:07.376882: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_val[0].shape\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(64,activation='relu', input_shape = input_shape))\n",
    "network.add(layers.Dense(256,activation ='relu'))\n",
    "network.add(layers.Dropout(0.25))\n",
    "network.add(layers.Dense(128,activation ='relu'))\n",
    "network.add(layers.Dropout(0.25))\n",
    "network.add(layers.Dense(64,activation ='elu'))\n",
    "network.add(layers.Dropout(0.25))\n",
    "network.add(layers.Dense(32,activation ='elu'))\n",
    "network.add(layers.Dropout(0.25))\n",
    "network.add(layers.Dense(16,activation ='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56cafded-d269-4bbf-8a05-06b9c5ef1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer='adam'\n",
    "loss='binary_crossentropy'\n",
    "metrics=['accuracy']\n",
    "\n",
    "network.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f141944a-1610-492b-9e78-65511cdbb1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 14:04:07.884093: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 960096000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 2s 19ms/step - loss: 0.4131 - accuracy: 0.8102 - val_loss: 0.2753 - val_accuracy: 0.8880\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.1991 - accuracy: 0.9287 - val_loss: 0.2742 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.1231 - accuracy: 0.9603 - val_loss: 0.3195 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.0641 - accuracy: 0.9807 - val_loss: 0.4115 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.5604 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 1s 17ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.5406 - val_accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.6903 - val_accuracy: 0.8790\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.6486 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.7250 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.8659 - val_accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 400\n",
    "\n",
    "history = network.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f50ac52-0e87-4b32-af54-a59b18f848af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0231 - accuracy: 0.8578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.02308189868927, 0.8577600121498108]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfb4c0-5e01-43ed-8630-e27ebe2bd82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb7f85-61c2-4b8d-b9f5-8c6e194d119e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cfb674-7a82-4b5b-9eee-f6559ca0993f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a94cd-2798-4948-a79e-5f13e6a68e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
