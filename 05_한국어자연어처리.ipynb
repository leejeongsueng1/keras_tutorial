{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03d3e07-5083-41c8-9e3d-d1cea2ab2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Komoran, Okt, Kkma, Hannanum\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d61e55-8ec2-4db0-ac3c-20d2ba9e2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kedi.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9baaf3e2-0031-4fb7-aaf9-aff962e07ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['명중', '명', '한글맞춤법']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = data.프로그램명[0]\n",
    "okt = Okt()\n",
    "okt.nouns(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4c397a-6866-4974-9561-88214126ada7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['명', '중', '명', '한글', '맞춤법']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran = Komoran()\n",
    "komoran.nouns(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a650b8ab-f3ab-40ac-8534-5467ae99923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '10명중9', '명', '중', '9', '한글', '한글맞춤법', '맞춤법']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkma = Kkma()\n",
    "kkma.nouns(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a360b9a-59bc-4eb7-bfd0-c6fe51275b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nouns(x):\n",
    "    return okt.nouns(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b574f5d-b7b0-42fc-b581-e45a6ee6e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"프로그램명\",\"소분류코드\",\"소분류\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d730fae9-a292-461e-b9ce-db956a5b0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['program_name','code','code_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb06b7d6-9134-4f7b-a146-f8fc5f8fbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff3071a-ddb8-4b8a-9ee6-f71304625170",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7024773e-437b-40ca-b8de-91106433aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d5ff8d8-0b9c-429a-a1a9-44e2648ce312",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.program_name.apply(make_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fb42c80-9fd4-49c8-9f4b-6b7b742e91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_one(x):\n",
    "    new_x = []\n",
    "    for i in x:\n",
    "        if len(i) > 1:\n",
    "            new_x.append(i)\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "508668dd-ae8e-4ee3-b074-9809544a6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(remove_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba21ed7d-05db-4a82-8e48-253e78bb87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7983f5c-e70a-4694-8b92-c472d88a293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = []\n",
    "for i in X:\n",
    "    full_text.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35858110-59e9-4843-959f-cc71b5e10fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_cnt = Counter(full_text)\n",
    "common_word = word_cnt.most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1454c3a2-9437-461e-b340-d44a1ba40cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_word = [ i for i,j in common_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e036541-80ea-4a44-bb19-f417a10d7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word = list(set(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71398021-17c8-4e25-9cb4-79d5567a571f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d8d9769-fb44-4922-a0e2-6d8eba77018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125167, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.program_name.values.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "970e31a3-e555-49e4-8208-348e1e3324ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word = [ i for i,j in common_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ceed6565-0a40-43dc-ac31-e1c410f38757",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = { k:v for k,v in enumerate(unique_word) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "391cdbc2-5638-4bc1-8f32-1dded74a4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = { v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c337cb6c-d616-4bd4-9201-eb76aed03b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정수 인코딩\n",
    "def label_encode(x):\n",
    "    encoded_x = []\n",
    "    for i in x:\n",
    "        encoded_x.append(index_word.get(i,0))\n",
    "    return encoded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24d2c4be-9aa4-4507-bc96-e5f1cd8de3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded = X.apply(label_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5344bec-d452-4f82-ad4f-b3bd831fbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_word(x,dimension=1000):\n",
    "    t = np.zeros((x.shape[0],dimension))\n",
    "    for k,v in enumerate(x.values):\n",
    "        for i in v:\n",
    "            if i < dimension:\n",
    "                t[k,i] += 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ad9f374-017b-4088-8200-b596cb3b1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = vectorize_word(label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c11ab94-c1e4-4bac-b059-6c7242e9e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_text = []\n",
    "for i in data.code:\n",
    "    code_text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0413497-95f4-45e3-841b-a2a7f4760b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_code = list(set(code_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18944cba-7433-4f41-ac46-8e05c954b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_index = { k:v for k,v in enumerate(unique_code)} \n",
    "index_code = { v:k for k,v in code_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "516d3e40-9ed1-4582-b778-e0dec6044552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_encode(x):\n",
    "    encoded_x = []\n",
    "    for i in x:\n",
    "        encoded_x.append(index_code.get(i,0))\n",
    "    return encoded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c11b4ea5-f4ea-4cc0-a85b-6b26e31d75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_code = []\n",
    "for i in data.code:\n",
    "    label_code.append(index_code[i])\n",
    "data['label'] = label_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca441d03-b153-4cc8-83a0-8d08e7bab0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8a2c4ed-0498-4a3a-b57f-fe2b8d7d50ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 125169 and the array at index 1 has size 125167",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mone_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/keras/lib/python3.8/site-packages/numpy/lib/index_tricks.py:412\u001b[0m, in \u001b[0;36mAxisConcatenator.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m scalars:\n\u001b[1;32m    410\u001b[0m         objs[k] \u001b[38;5;241m=\u001b[39m objs[k]\u001b[38;5;241m.\u001b[39mastype(final_dtype)\n\u001b[0;32m--> 412\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matrix:\n\u001b[1;32m    415\u001b[0m     oldndim \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 125169 and the array at index 1 has size 125167"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(np.c_[one_hot,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138814cb-f891-443d-a94b-b9d638673c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(dt.index,len(dt.index),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d47fdd-9828-42b8-a08e-4b49e18cf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx = idx[:int(0.8*len(idx))]\n",
    "te_idx = idx[int(0.8*len(idx)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331de241-5a5f-46a8-823c-6d51680b64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dt.iloc[tr_idx,:1000].values\n",
    "X_test = dt.iloc[te_idx,:1000].values\n",
    "y_train = dt.iloc[tr_idx,1000:].values\n",
    "y_test = dt.iloc[te_idx,1000:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47086f1d-95be-4d8d-9f67-9717dcae0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c568a1-42c5-4969-a138-ebd7de26eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,activation='relu',input_shape=(input_shape,)))\n",
    "model.add(Dense(128,activation='sigmoid'))\n",
    "model.add(Dense(output_shape,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82c4b6-f414-453f-b0e8-7bd6c60a2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d67070-b8d0-46dd-8d2d-50d3741042f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'rmsprop'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=loss,\n",
    "             metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39add858-6738-45c6-97fc-16c77fa40371",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 300 \n",
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2543a3-15a6-4568-a6c0-815ad666b4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fa09b-17de-4b78-8156-8b9d018c4182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dded0d-77b0-4c07-a9d4-6055d965d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_sentences(X_train):\n",
    "input : np.array: ([123,12,15,48],[51,74,63], ...)\n",
    "output : list:['text', 'text', ...]\n",
    "\n",
    "\n",
    "동작\n",
    "\n",
    "np 어레이를 리스트로 typecasting 후\n",
    "내부 리스트 하나씩(sentence) 읽어와서\n",
    "원소(index) 하나씩 단어사전(index_word) 참조\n",
    "만약 index가 사전에 최댓값 보다 크다면 \n",
    "사전 참조하지 않고 continue\n",
    "단어 단위를 더할때에는 사이에 공백(' ')추가\n",
    "리스트에 문장을 넣을 때 양 끝에 공백 벗기고(.strip())추가\n",
    "리스트 반환\n",
    "\n",
    "\"\"\"\n",
    "def make_sentences(dummy):\n",
    "    dummy_list = []\n",
    "    for sentence in list(dummy):\n",
    "        context = ''\n",
    "        for index in sentence:\n",
    "            if index > max_vlaue:\n",
    "                continue\n",
    "            context += index_word[index]+' '\n",
    "        dummy_list.append(context.strip())\n",
    "    return dummy_list\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "contexts_to_index(sentence_list):\n",
    "input: text_list: ['abc asv', 'bdvs brrwab brb', ...] \n",
    "output: index_list: [[1594, 2456, 24154, 1514, 1248, 12],[154,87,7,213,8], ...]\n",
    "\n",
    "동작\n",
    "인덱스리스트의 내부 리스트(sentence)를 하나씩 가져와서\n",
    "만약 sentence에 공백이 존재하면 (하나 이상의 단어라는 의미)\n",
    "word_list를 sentence.split으로 생성 단어 리스트\n",
    "단어리스트를 보면서 index_word를 사전참조해\n",
    "tmp에 append\n",
    "tmp를 index_list에 담는다.\n",
    "\n",
    "만약 공백이 존재하지 않으면? --> 단일 단어\n",
    "바로 index_word에 사전참조하여 [리스트에 담아서] index_list에 담는다.\n",
    "\n",
    "index_list 반환\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def contexts_to_index(sentence_list):\n",
    "    index_list = []\n",
    "    for sentence in sentence_list:\n",
    "        if \" \" in sentence:\n",
    "            tmp = []\n",
    "            word_list = sentence.split()\n",
    "            for word in word_list:\n",
    "                try:\n",
    "                    tmp.append(word_index[word])\n",
    "                except:\n",
    "                    try:\n",
    "                        tmp.append(word_index[word.strip()])\n",
    "                    except:\n",
    "                        pass\n",
    "                    # 만약 안되면 추가\n",
    "                    tmp.append(0)\n",
    "            index_list.append(tmp)\n",
    "        else:\n",
    "            index_list.append([word_index[sentence]])\n",
    "    return index_list\n",
    "\n",
    "\"\"\"\n",
    "make_full_text(sentence_list):\n",
    "input:\n",
    "output:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def make_full_text(sentence_list):\n",
    "    full_text = ''\n",
    "    for sentence in sentence_list:\n",
    "        full_text += sentence + ' '\n",
    "    return full_text.strip()\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
